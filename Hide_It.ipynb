{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simplejson in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.19.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Scep9wt2Q_Rn"
   },
   "outputs": [],
   "source": [
    "# CONNECT TO REDDIT THROUGH UAUTH\n",
    "\n",
    "import requests\n",
    "\n",
    "# developer account info\n",
    "client_id = \"iBUlXklHFr1KDzhJ7BVdAw\"\n",
    "secret = \"9xDTwhK5AkhCKm27i0uM9UcQcH_DjQ\"\n",
    "uname = \"hide-it-AI4G\"\n",
    "pw = \"AI4GoodLab\"\n",
    "\n",
    "  # nrequest OAuth token\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, secret)\n",
    "\n",
    "# login method (username & pw)\n",
    "data = {'grant_type': 'password', 'username': uname, 'password': pw}\n",
    "\n",
    "# setup header info (brief description of the app from the github)\n",
    "headers = {'User-Agent': 'Hide-It: https://github.com/Rain1618/Hide-It (use for training a model in the AI4Good Lab, Montreal cohort)'}\n",
    "\n",
    "# send request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "\n",
    "# convert response to JSON and pull access_token value\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "# add authorization to headers dictionary\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# while the token is valid (~2 hours) add headers=headers to requests\n",
    "request = requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x__3RkJ33gj0",
    "outputId": "4dc8123c-d62c-455b-f30f-8dfc55d91d86"
   },
   "outputs": [],
   "source": [
    "# SETUP TRIGGER CATEGORIES\n",
    "\n",
    "# target subreddits\n",
    "ed_subreddits = ['EatingDisorder', \n",
    "                 'AnorexiaNervosa', \n",
    "                 'Bulimia', \n",
    "                 'Eating_disorders', \n",
    "                 'BingeEatingDisorder', \n",
    "                 'EDAnonymous'\n",
    "                ]\n",
    "abuse_subreddits = ['domesticviolence',\n",
    "                                'NarcissisticAbuse',\n",
    "                                'TrueNarcissisticAbuse',\n",
    "                                'abusesurvivors',\n",
    "                                'abusiverelationships',\n",
    "                                'emotionalabuse'\n",
    "                               ]\n",
    "addiction_subreddits = ['alcoholism',\n",
    "                        'addiction',\n",
    "                        'opiatesRecovery',\n",
    "                        'stopdrinking',\n",
    "                        'stopsmoking',\n",
    "                        'stopspeeding'\n",
    "                       ]\n",
    "suicide_subreddits = ['suicideWatch',\n",
    "                      'TimeToGo',\n",
    "                      'SuicideBereavement',\n",
    "                     ]\n",
    "sexual_violence_subreddits = ['SexualAssault',\n",
    "                             'AdultSurvivors',\n",
    "                             'rape',\n",
    "                            ]\n",
    "\n",
    "safe_subreddits = ['CasualConversations',\n",
    "                  'UpliftingNews']\n",
    "\n",
    "trigger_categories = {\"eating disorders\":ed_subreddits, \"abuse\":abuse_subreddits, \n",
    "                      \"addiction\":addiction_subreddits, \"suicide\":suicide_subreddits, \n",
    "                      \"sexual violence\":sexual_violence_subreddits, \"safe\":safe_subreddits}\n",
    "\n",
    "target_info = ['title', 'selftext', 'subreddit', 'name']\n",
    "  \n",
    "new_safe = ['dadjokes', 'Glitch_in_the_matrix', 'TravelNoPics', \n",
    "            'worldbuilding', 'rpg', 'ontario', 'AskComputerScience', \n",
    "            'AskPhotography', 'AskEconomics', 'AskEngineers', \n",
    "            'AskHistorians', 'changemyview', 'suggestmeabook', \n",
    "            'askphilosophy', 'tipofmytongue', 'santashelpers', \n",
    "            'composites']\n",
    "new_trigger_categories = {\"new safe\": new_safe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dadjokes\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "Glitch_in_the_matrix\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "TravelNoPics\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "worldbuilding\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "rpg\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "ontario\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "AskComputerScience\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "AskPhotography\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "AskEconomics\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "AskEngineers\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "AskHistorians\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "changemyview\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "suggestmeabook\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "askphilosophy\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "tipofmytongue\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "santashelpers\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "composites\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "8500\n"
     ]
    }
   ],
   "source": [
    "# DOWNLOAD DATA FROM API TO CSV\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "for cat_name,cat_subs in new_trigger_categories.items():\n",
    "    \n",
    "    data = pd.DataFrame(columns = ['title', 'selftext', 'subreddit', 'name', 'trigger'])\n",
    "    limit = 100\n",
    "    search_after = None\n",
    "    \n",
    "    for sub in cat_subs:\n",
    "        \n",
    "        print(sub)\n",
    "        count = 0\n",
    "        search_after = None\n",
    "\n",
    "        while (count < 500):\n",
    "\n",
    "            url  = \"https://oauth.reddit.com/r/\" + sub + \"/new.json\"\n",
    "            res = requests.get(url, headers=headers, params={'limit': limit,'after': search_after})\n",
    "            count = count+limit\n",
    "            posts = res.json()['data']['children']\n",
    "            \n",
    "            print(len(posts))\n",
    "\n",
    "            for post in posts:\n",
    "                \n",
    "                post_data = {key: post['data'][key] for key in target_info}\n",
    "                post_data['trigger'] = cat_name\n",
    "                data = data.append(post_data, ignore_index=True)\n",
    "\n",
    "            # if close to going over request limit, sleep for time remaining until reset\n",
    "\n",
    "            if float(res.headers['X-Ratelimit-Remaining']) < 5:\n",
    "                time.sleep(float(res.headers['X-Ratelimit-Reset']))\n",
    "\n",
    "            # save the last post as the index to search before, otherwise will get duplicates on iterations\n",
    "            search_after = data['name'].iloc[len(data) - 1]\n",
    "\n",
    "    # save data from this subreddit\n",
    "    data.to_csv(cat_name + \"_data.csv\", encoding='utf-8')\n",
    "    print(len(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
